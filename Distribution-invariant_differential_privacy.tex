
\chapter{Distribution-Invariant Differential Privacy}

This paper has very wierd organization.
Key point: the trade-off between privacy protection and statistical accuracy


The key point of the paper is  that one can reconcile both accuracy and privacy, which we achieve by preserving the original data’s distribution.
it is believed
that there is a trade-off between statistical accuracy and differential privacy.


It transforms and perturbs the data and employs a suitable transformation to recover the original distribution.

The first achieves privacy protection by either a privatization mechanism or a privatized sampling method, including the Laplace mechanism [19, 20], the exponential mechanism [43], the minimax optimal procedures [15], among others.

The second achieves differential privacy via privatization for a category of models or algorithms, such as deep learning [1], boosting [21], stochastic gradient descent [2], risk minimization [7], random graphs [38], func- tion estimation [30], parametric estimation [4], regression diagnostics [8], and top-k selection [16].

One main challenge is that existing privatization mechanisms protect data privacy at the expense
of altering a sample’s distribution

DIP approximately maintains statistical accuracy even with strict privacy protection in that it does not suffer from the trade-off between accuracy and privacy strictness


These characteristics enable us to perform data analysis without sacrificing statistical accuracy, as in regression, classification, graphical models, clustering, among other statistical and machine learning tasks
% \begin{itemize}
%   \item many convergence rate $n^{-1/3}$
%   \item Key point is: continuous mapping theorem for the location of maximum point.
%   \item 
% \end{itemize}

% \marginpar{
%   \begin{marginnotes}
%     The paper is a very nice material for understanding the core idea and techniques of empirical process.

%     Main reference of this paper is in the lecture notes of Pollard ``Empirical process: Theory and applications'' 1990 version.
%   \end{marginnotes}
% }

DIP’s privatization process consists of three steps. 
\begin{itemize}
    \item First, DIP splits the original sample randomly into two independent subsamples, hold-out and to-be-privatized samples, both are fixed after the split. 
    \item Second, it estimates an unknown data distribution by, say, the empirical distribution on the hold-out sample, which is referred to as a reference distribution. \item Third, we privatize the to-be-privatized sample through data perturbation, which (i) satisfies the requirement of differen- tial privacy, and (ii) preserves the reference distribution approximating the original distribution. As a result, DIP is differential private on the to-be-privatized sample while retaining the original distribution asymptotically, c.f., Theorem 2.
\end{itemize}

\Kchange{need to estimate the empirical distribution.}


For univariate data, 
(1)do probability-integral transformation

(2)random Laplace noise to perturb and mask the data

(3) we design a new function transforming the obfuscated data to follow the reference distribution approximating the original data distribution


For multivariate data,
we propose to apply the probability chain rule [51], in place of privatizing each variable independently


Detail methodology

First, we focus on \Kchange{the case where the underlying distribution is known.} The cumulative distribution function is $F$.

For continuous variable,
\begin{itemize}
    \item apply F on the random sample $Z_i$ and get $F(Z_i)$ which follows uniform distribution.
    \item add independent noise $e_i$ to the $F(Z_i)$ where $e_i$ follows Laplace distribution $Laplace(0,1/\epsilon)$
    \item Finally, we apply a nonlinear transformation $H$ to produce a privatized sample that follows the original distribution $F$.
\end{itemize}

The $H$ dependes on the data type.
For continuous variable,
$G$ converges $F(Z_i) + e_i$ to uniform distribution.

Then $F^{-1}$ converges $G(F(Z_i) + e_i)$ to original function.
Then 
$H(\dot) = F^{-1} \circ G(\dot)$

Details of $G$ in Appendix S1.1.


$\hfill \square$